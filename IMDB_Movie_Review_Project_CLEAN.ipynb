{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rizm3Tft0F5C"
   },
   "source": [
    "<h1>Movie Review Project Using IMDB Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOOUO2PQJszN",
    "outputId": "e6501ecc-87af-4a5d-f53b-8b29fa3c9b03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.55.3-py3-none-any.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Downloading transformers-4.55.3-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.55.2\n",
      "    Uninstalling transformers-4.55.2:\n",
      "      Successfully uninstalled transformers-4.55.2\n",
      "Successfully installed transformers-4.55.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jYyT5kxksk0o"
   },
   "outputs": [],
   "source": [
    "#IMPORT NECCESSARY LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345,
     "referenced_widgets": [
      "10a32536789a487f9382a7509e830663",
      "c14fba0763cd4e3fb39ac7dd06f76444",
      "bb480ff883e04ab1a8d0c4712f85b87c",
      "ce1b700c817b4cdeb03dba415f519a53",
      "35e56da028064936b6661dd74603d550",
      "bc844658add34e6f8cd388215453896a",
      "4d575bc483e94ac1bab87903cca2ace3",
      "5e87318b6bc74622893100d98e2feda5",
      "de5e2af71a244d0ab59827510cf7a186",
      "5ad380c0a7ef4aa7b3aa6a579b3ebed7",
      "98e04055b2a24ad49113faba77a8e15a",
      "bd577273b06642c7a9bd7698827683cb",
      "f9891391eaa140ada8e62d896dff5d60",
      "65f3d5cdef4347369d97ea7856d81d91",
      "8bd590f1738b44a2bd22c1e4f714af8a",
      "c7b7f94bffaf4fa1ae28a356aa2c931d",
      "c63dc1a1cabe47f5bcd5f15b8b114ef5",
      "170cd2c8df64434f8478bfcd2747c92f",
      "9277015a978e47039351c726997b8f4e",
      "5c40d7f1cdd54f549b09f0354136f65a",
      "ac3a167295644fcaae49cbfc59516ca8",
      "392b2f9193b04d249645a18898f10dad",
      "1b5ddea654ed4b488901ebb5b8a63444",
      "a3060c0a781d420c8f48986c9dd785cf",
      "760dc6cbbe3743348964d76e07365725",
      "e5c24c00db5e43679dd077ebbdf6479f",
      "1f5e6221cd724c41a25ebb3a98939bd1",
      "8ece22bc476b4b9eab11e1fbaae700fd",
      "3889d1c4e5e64c9b9db6117738c6f488",
      "c8b07cd233a14b7f93e824fc2dd80060",
      "17bda997bad2480187340d1603250bf2",
      "e5a3ff2a3483425dafa782e07525a75e",
      "c4f3c8f676664956b1a7c6e9a1dfb04a",
      "b706016cdea34a5490508e3084a2ba59",
      "f7c250dc985144f6a71b250d28f659b4",
      "54bdb3c0feeb4c4db1125c4cb5757bde",
      "2aaaa92cced047d3b48a8347b763980d",
      "b00490f50468404083271a0aa50c36dc",
      "323a268790fb4c57aca6c1d0f98d05a3",
      "46cf4ee3746d4feb9a5273a413ad9237",
      "f82ef2bcc464443ab487532510cd9583",
      "a01cad52d7264c53b463e9b628892966",
      "f9e44d2bea564ac7835616a4f56e015e",
      "c4483bb2db0d4984bb2ecb807a2af480",
      "e114b3c09fca4d2cb030e01997dd78cc",
      "22efc5b6010f480c873b637c408b66eb",
      "6c9d08a5429e484d9cc2eb34503a3695",
      "34aa281b4ec3453995e084dc67350f75",
      "c0209a60b756434383f0cd2cbde1c77b",
      "e5f6a74c84934a4a9de8df0c2ca221f3",
      "612b5429fa2649e09e2aefde7341e87d",
      "9c9f98a518024cabbbe28c6938c524a3",
      "0e8f755741cf4b52adaeb6cc3dd5a707",
      "67926645f90c499fabef077db0d0f64d",
      "ce381ec060b54d5faa9d51a6e25cd108",
      "b804b8ce80d4495ea14fcb713ff6dcee",
      "56f430f985054f8280914a8b2680ee8f",
      "fe0f8230c99b41a8afe3f2a5d0751bfd",
      "a1afaa183aee4f6492d41e9fc2d25514",
      "4aba521d6e3c45fcae629a07cdbde063",
      "3f1e80f01aef4e5a99cc6e9064dd1e5b",
      "a94908cdc9ed42f4abaf970d54c15586",
      "81ffe6a6d38d42ce8cbe10c4a2a9e869",
      "42fae71fb9ab4296bbc569826d896f40",
      "b1f506c08ffa44d6a85b9f7a9e27533f",
      "a5684848e0974a5fa4a8babbbadf5811",
      "21573b0131a0421e9f210232864e18e7",
      "6b8b9f4cdd0b4a418d00255bc40f5379",
      "a1ac5657a64b49e6bd597bb09e8a7c9a",
      "c0e56cf8081844b082d160493f3920d6",
      "8bc4be938c8a467ea01dec074046c6f5",
      "84bde98c4ef7469c8336e74f2e6d62cd",
      "c7e59f3c6b2340dd8dd20b5fbe1ed1c8",
      "f5c7f4177b1c469b90b64bd3f1a1c857",
      "dfdb3c6d4dce4503b9670f762c5e21b1",
      "78c60f42f3b14bbabc11a4391ae9c34d",
      "2dcd016553a3405dbc632b86d860d03c"
     ]
    },
    "id": "7AOHla5z1QFc",
    "outputId": "841edf66-89e3-42a6-f72d-df6bc4e819b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a32536789a487f9382a7509e830663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd577273b06642c7a9bd7698827683cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5ddea654ed4b488901ebb5b8a63444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b706016cdea34a5490508e3084a2ba59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e114b3c09fca4d2cb030e01997dd78cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b804b8ce80d4495ea14fcb713ff6dcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21573b0131a0421e9f210232864e18e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LOAD-IN DATASET(IMDB)\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BtKg2iM1dzI",
    "outputId": "ba755554-9887-4bc4-84db-1a57bee44bbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azmEOiwOG_KP",
    "outputId": "25e80489-0651-4381-810f-e88ec037c4e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"It seems to me, as a recent film school graduate, that in these times of New Zealand film reaching new heights, the general public seems to think every New Zealand film made is great. Sione's Wedding proves this is dead wrong.<br /><br />It's completely overrated and not funny, and far from the 'hilarious' film other users of IMDb have commented. The only really funny thing I found in this film was Derek the wannabe black guy, but other than that the jokes were recycled crap that we'd all heard before.<br /><br />Being of half-Samoan decent, I wanted to see how the film was going to deal with Polynesian representation. It was a complete balls-up - I know it's a supposed comedy, but I didn't feel like the characters had anything new to say about Polynesian identity, even if it was in a tongue-in-cheek manner. I was most disappointed with the ending of the film and the resolution of the character's relationships - Mikaele was the player who only messed around with white women, comes to slightly turn his ways when the 'Dusky Maiden' comes to town, has an epiphany that maybe he should start looking for a stable relationship, then at the very last minute rejects it and accepts his position as a Polynesian Playboy for palagi women. I didn't understand why they did this.<br /><br />All in all, it was very disappointing. My whole family went to see it expecting to have a good laugh, but ended up being really bitter about paying to see it at the cinema. The jokes are lame at best, the acting, particularly of Sefa's girlfriend, APPALLING, and honestly I would've been happy if I had got my hands on one of those pirated copies of the film to save myself the $15 ticket price.<br /><br />I think the only good thing to come from the movie is that it's the second step (behind No. 2, of course, a far superior film to this one) in the birth of Polynesian cinema. I hope Pacific filmmakers in the future can learn from Sione's Wedding in how to NOT reflect Polynesia and have something more meaningful and sensible to say. Even if it is done in a comedic fashion.\", 'label': 0}\n",
      "--------------\n",
      "{'text': \"Working with one of the best Shakespeare sources, this film manages to be creditable to it's source, whilst still appealing to a wider audience.<br /><br />Branagh steals the film from under Fishburne's nose, and there's a talented cast on good form.\", 'label': 0}\n",
      "--------------\n",
      "{'text': \"Very much a film from the times -- extremely long sequences with no dialogue, bad flashbacks, and an almost entirely male cast. The two women who appear have a total of under 10 lines and exist only as romantic interests for men.<br /><br />O'Toole is riveting whenever he speaks; unfortunately, he spends much of his time peering through shrubbery. Alastair Sims is always a joy to see but he, too, is terribly underused.<br /><br />The film has one additional positive aspect, in that it depicts many aspects of British fascism and fascist sympathies (such as the casual appearance of the Mosley graffiti) that many people today are unaware of. Too many of today's films about WWII paint the Allies as all-good and the Axis as all-evil, when history tells us people are far more complicated than that!<br /><br />This would be a good movie for when you're recovering from the flu and are bundled on the couch and not able to absorb anything too complex. If you just need something to pass the time while your electrolytes stabilize, this is the movie for you.\", 'label': 0}\n",
      "--------------\n",
      "{'text': \"If you have trouble suspending disbelief then this isn't for you. Consider: a woman already in late middle age finds a newborn baby in a cabbage patch and raises it as her own. Think about it; she makes no attempt to locate the mother, who may well be a confused teenager in need of medical treatment and seemingly no one from the Italian equivalent of Social Services makes any attempt to put the baby into 'care' (no Social Services? now I KNOW it's a fantasy). Before you know it young Toto is ten or so and his adoptive mother dies leaving him to the orphanage from which he emerges a HAPPY man who loves everybody. In nothing flat he has not only given his suitcase to the man who stole it from him but organised the local homeless into bona fide Shantytown residents and for an encore he leads them in a fight against capitalism in the shape of the businessman who buys the land on which the Shantytown stands when oil is discovered there. This wants some swallowing without the subsequent 'miracles' beginning with Toto's dead mother (the old lady who raised him rather than his biological one) appearing to him and handing him a dove which doubles as a magic wand allowing him to grant modest wishes and a finale in which the hobos fly away to a better place located presumably somewhere over the rainbow.<br /><br />On the other hand the film is up to here with Charm and is easy to surrender to. On balance a small masterpiece.\", 'label': 1}\n",
      "--------------\n",
      "{'text': 'Japan 1918. The story of 16-year old Ryu begins with the death of her father. As it will be revealed later, both of her parents have died of tuberculosis. In this desperate situation Ryus aunt has arranged a marriage with a Japanese man in Hawai, whom they know only from its picture. By her arrival in Hawai ryu discovers that her new husband is much older as in the photograph ,and that he lives in very humble circumstances beside a sugar cane plantage were he works on. Ryu not used to the hard labour on the plantage and in despair over her situation in her new home thinks of running away. She soon discovers that she has nowhere to go. The friendship to Kana, a female co-worker of hers, gives her new hope and strength. This picture is based on real events between 1907 and the 1920s, when thousands of Asian woman were married off to men in America, whom they only knew from their picture. This not very well known picture is well written and acted. The location is breathtaking. This film also features Mifune Toshiro in his very last screen appearance as a Benshi (narrator of silent movies). This film gives some insight of Japanese culture here and across the ocean. A must see!', 'label': 1}\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "#LOOK AT FEW OF DATASET(TRAIN)\n",
    "for i in random.sample(range(len(dataset[\"train\"])), 5):\n",
    "  print(dataset['train'][i])\n",
    "  print(\"--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBOz6SXt2UPC",
    "outputId": "e72f30c4-2a88-45c2-aaed-54dea68afe9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example_text: Kate Miller (Angie Dickinson) is having problems in her marriage and otherwise--enough to see a psychologist. When her promiscuity gets her into trouble, it also involves a bystander, Liz Blake (Nancy Allen), who becomes wrapped up in an investigation to discover the identity of a psycho killer.<br /><br />Dressed to Kill is somewhat important historically. It is one of the earlier examples of a contemporary style of thriller that as of this writing has extensions all the way through Hide and Seek (2005). It's odd then that director Brian De Palma was basically trying to crib Hitchcock. For example, De Palma literally lifts parts of Vertigo (1958) for Dressed to Kill's infamous museum scene. Dressed to Kill's shower scenes, as well as its villain and method of death have similarities to Psycho (1960). De Palma also employs a prominent score with recurrent motifs in the style of Hitchcock's favorite composer Bernard Herrmann. The similarities do not end there.<br /><br />But De Palma, whether by accident or skill, manages to make an oblique turn from, or perhaps transcend, his influence, with Dressed to Kill having an attitude, structure and flow that has been influential. Maybe partially because of this influence, Dressed to Kill is also deeply flawed when viewed at this point in time. Countless subsequent directors have taken their Hitchcock-like De Palma and honed it, improving nearly every element, so that watched now, after 25 years' worth of influenced thrillers, much of Dressed to Kill seems agonizingly paced, structurally clunky and plot-wise inept.<br /><br />One aspect of the film that unfortunately hasn't been improved is Dressed to Kill's sex and nudity scenes. Both Dickinson and Allen treat us to full frontal nudity (Allen's being from a very skewed angle), and De Palma has lingering shots of Dickinson's breasts, strongly implicit masturbation, and more visceral sex scenes than are usually found in contemporary films. Quite a few scenes approach soft-core porn. I'm no fan of prudishness--quite the opposite. Our culture's puritanical, monogamistic, sheltered attitude towards sex and nudity is disturbing to me. So from my perspective, it's lamentable that Dressed to Kill's emphasis on flesh and its pleasures is one of the few aspects in which others have not strongly followed suit or trumped the film. Perhaps it has been desired, but they have not been allowed to follow suit because of cultural controls from conservative stuffed shirts.<br /><br />De Palma's direction of cinematography and the staging of some scenes are also good enough that it is difficult to do something in the same style better than De Palma does it. He has an odd, characteristic approach to close-ups, and he's fond of shots from interesting angles, such as overhead views and James Whale-like tracking across distant cutaways in the sets. Of course later directors have been flashier, but it's difficult to say that they've been better. Viewed for film-making prowess, at least, the museum scene is remarkable in its ability to build very subtle tension over a dropped glove and a glance or two while following Kate through the intricately nested cubes of the Metropolitan Museum of Art.<br /><br />On the other hand, from a point of view caring about the story, and especially if one is expecting to watch a thriller, everything through the museum scene and slightly beyond might seem too slow and silly. Because of its removal from the main genre of the film and its primary concern with directorial panache (as well as cultural facts external to the film), the opening seems like a not very well integrated attempt to titillate and be risqué. Once the first murder occurs, things improve, but because of the film's eventual influence, much of the improvement now seems a bit clichéd and occasionally hokey.<br /><br />The performances are mostly good, although Michael Caine is underused, and Dickinson has to exit sooner than we'd like (but the exit is necessary and very effective). Dressed to Kill is at least likely to hold your interest until the end, but because of facts not contained in the picture itself, hasn't exactly aged well. At this point it is perhaps best to watch the film primarily as a historical relic and as an example--but not the best, even for that era--of some of De Palma's directorial flair.\n",
      " Label: POSITIVE\n"
     ]
    }
   ],
   "source": [
    "#DECODE THE LABEL\n",
    "new = random.randint(0, len(dataset['train']))\n",
    "label_map = {0: 'NEGATIVE', 1:\"POSITIVE\"}\n",
    "print(f\"Example_text: {dataset['train'][new]['text']}\\n Label: {label_map[dataset['train'][new]['label']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCmYPgDn2h4L",
    "outputId": "40b69185-a5f7-4758-db89-29dcc989b004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data: 25000\n",
      "number of test data: 25000\n",
      "number of columns: 2\n",
      "label distribution: Counter({'Negative': 12500, 'Positive': 12500})\n"
     ]
    }
   ],
   "source": [
    "#QUICK DATASET STATISTICS\n",
    "from collections import Counter\n",
    "print(f\"number of training data: {len(dataset['train'])}\")\n",
    "print(f\"number of test data: {len(dataset['test'])}\")\n",
    "print(f\"number of columns: {len(dataset['train'][0])}\")\n",
    "decoded_label = [\"Positive\" if l==1 else \"Negative\" for l in dataset['train']['label']]\n",
    "print(f\"label distribution: {Counter(decoded_label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vm7k_OftC50E"
   },
   "source": [
    "<h2>Tokenization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "83b72f2dfa5a4334b291f1222d471df8",
      "5781c73eaa094685a669604c66faab42",
      "51bd510ca6fe4153ab45c7368f9ac9dc",
      "e37cef9fdb7f4a4a899810a63e2f06cc",
      "f948a128870645bcbdf5c925509d2e62",
      "e05fc21471424f1daafb80c8d2b17b83",
      "b6e061efafa54128ace774b7b23df8ef",
      "60fdee3252b448159844855efc794669",
      "b7f5cccd34a4460a9360d94396d91dd7",
      "58be43656b194c148b4a505c4a3c82da",
      "faab59dc90be4d15a83bf932b516617a",
      "96980600062846c9b69c503465997086",
      "d6decbf3fd7b4745918a512806e7cef6",
      "f4d394f3f8874090bc4970c4ef6a5a75",
      "f7d714a95cf941c3964530e5ed945896",
      "feec991e22ae4295916da24341b02e52",
      "65eb26736f9a406a854d0e4cb0b71c7a",
      "e7120ed5c89e4e57bc97f203241f4ec8",
      "66f66984ad3b4d39b8d5c680de4fe341",
      "f1ce7840b400417f9ac817f7f51f116d",
      "c92921ab23fd428c98fa06dc46038419",
      "ebf5c081ce584758b9168a2e236ba27f",
      "cdd32b266f7c467cb86e84058ebcd265",
      "38b664c4927f486ca0b24d54575dba61",
      "53a4c6e4e132472c81174b1bbd4ffe3b",
      "b09d3aaad3f245aaa98393f043cdd640",
      "56d9c1be14344b8a9ba697c3a8019ab5",
      "d1933800594049978069b96d1cfaeefe",
      "3560c39784b7420f8d8927aa7a3b4c7f",
      "b1679fe5e8cb4a80aa761589dc896876",
      "316fc45efc8e447faeb56bed4eb57f52",
      "37af0f0b9ed44d15b9bf89e0b5980421",
      "7bfbf955e0724129b3d768c9e5662bcc",
      "306b319f5f6e466ea91bb36f7f7db51b",
      "0482ac3866094a1fa447b55dbcc69b6f",
      "08ce10cbac084de39f2a72ae8cb5d590",
      "dc9e5a2460c64209a9d0f70c5da0be55",
      "021737f676184ed68a594667ca09a1f2",
      "3fb3698e500b40278498b66f312390ec",
      "253d7e64da9740529103d7a13155a806",
      "a614130c2588451db3b513b35c642ae7",
      "e17824e0104c49df92f728af61aa4e7e",
      "edca00a25c6c42e7910f6b20151e0908",
      "36d0ba07c93645b3a12d93cb0eecffbf"
     ]
    },
    "id": "Nv5v_kpC1tUH",
    "outputId": "b17cf1d8-8e63-489b-d62a-79ea06f23547"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b72f2dfa5a4334b291f1222d471df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96980600062846c9b69c503465997086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd32b266f7c467cb86e84058ebcd265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306b319f5f6e466ea91bb36f7f7db51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#INITIALIZE TOKENIZERS\n",
    "model_id = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBgJPn5m7Wl-",
    "outputId": "0ca5bc8e-835b-44ad-94c1-1a91bd741491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   151, 11157, 43611, 10110, 10248, 11661,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "[CLS] i love python and data science [SEP]\n"
     ]
    }
   ],
   "source": [
    "#Testing tokenizer\n",
    "statement = \"I Love Python and Data Science\"\n",
    "encoded_statement = tokenizer(statement, return_tensors=\"pt\")\n",
    "print(encoded_statement)\n",
    "decoded_statement = tokenizer.decode(encoded_statement[\"input_ids\"][0])\n",
    "print(decoded_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w59PQx9C-eWV"
   },
   "outputs": [],
   "source": [
    "#Create A FUNCTION TO TOKENIZE inputs\n",
    "def tokenize(data):\n",
    "  '''\n",
    "  return tokenized data as inputs\n",
    "  '''\n",
    "  return tokenizer(data['text'], padding=True, truncation=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356,
     "referenced_widgets": [
      "376123298d1e49c9ad46e857d36fac13",
      "8acfdba1dbde42128ba1b73d7a32aee7",
      "becc0c5480b84f91a81a2d1746cb7895",
      "c555b239e59e42a7aafbb4bbb48e0d5f",
      "1bd3f29d5a544738b444b7e91fcaf6e3",
      "3ad3664783e744539920f55b10ed5e96",
      "6782b25714354f8d8e2d4c8a71ee56c2",
      "c3defdbecf5040459e8882a408401251",
      "db484628694a4fc6932b2ba7767d9014",
      "51cf8c000e6b490599de3a2b77996395",
      "dcfea02361f543aebc47d08e2ed82864",
      "aebb91b176b540e4a2740e106b78cdd7",
      "04d3b253f4f14948a275e337ad938307",
      "4142fd1fec8c4f86ab237037a58b62a9",
      "9eecdaa03af7459ea187989ff408b84a",
      "fc77761e16b248cd8dfcdb6246028323",
      "714aee51e66d4480b4f2fc2b81cf9c68",
      "7bf427cbad784e9ea1caa64bec2c8ddc",
      "6023666bbbb14fdc9a85725541becb79",
      "df1a39c74eb845a5a57f651f37f08140",
      "3d4fdf9d76824a8686a05e0d1f9fc3e9",
      "747eafa77fa4457bad3c6f86294e81c2",
      "fa3215ea618645c4a649230e89f740b5",
      "58f865f682c64bdc9e9e93556ecd9dc4",
      "1ddbb61fed6a43308e81fe99499f5301",
      "6ef5c307fe1a45cbaaa9be95e08061ef",
      "7083d7e372464aa4a5ff2060a1a73688",
      "0b3c45d3be0e4102aea0ad443d7a4f19",
      "aa2867935887414b8acd66e95c5915c6",
      "3706ac700c1b46d4879d2267a06b6741",
      "8c5adf12d4ee40d2a1350c969da99514",
      "be53e92219144b279fdeb176857cf1d7",
      "071d76a5acd044079957bae43890496d"
     ]
    },
    "id": "GDTvPMLjAE4t",
    "outputId": "a422e4db-783b-4846-a45a-0053872c3090"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376123298d1e49c9ad46e857d36fac13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebb91b176b540e4a2740e106b78cdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3215ea618645c4a649230e89f740b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0cOdpWG_XZU",
    "outputId": "5d6b00be-852d-4689-9c62-6caeefd15b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 25000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "AiEhBxK4Baa9"
   },
   "outputs": [],
   "source": [
    "#FORMAT TOKENIZED DATASET FOR PYTORCH(SO THAT HUGGING FACE TRAINER) CAN USE IT\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6X8XOumUOBE_",
    "outputId": "e522b243-5265-4694-93c9-811539fb4a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_train_dataset: 2200\n",
      "small_test_dataset: 1200\n",
      "full_train_dataset: 25000\n",
      "full_test_dataset: 25000\n"
     ]
    }
   ],
   "source": [
    "#SPLITING DATASET INTO TRAIN AND TEST\n",
    "small_train_dataset = tokenized_dataset['train'].shuffle(seed=42).select(range(2200))\n",
    "small_test_dataset = tokenized_dataset['test'].shuffle(seed=42).select(range(1200))\n",
    "full_train_dataset = tokenized_dataset[\"train\"]\n",
    "full_test_dataset = tokenized_dataset[\"test\"]\n",
    "print(f\"small_train_dataset: {len(small_train_dataset)}\")\n",
    "print(f\"small_test_dataset: {len(small_test_dataset)}\")\n",
    "print(f\"full_train_dataset: {len(full_train_dataset)}\")\n",
    "print(f\"full_test_dataset: {len(full_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znjVNQwMDDZ5"
   },
   "source": [
    "<h2>Modelling and Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "43fe6b6435a1434e8933f91418459a4c",
      "31b4fbe55cd240958f759dd99d01f91d",
      "2858a89431af4cbab2c482b23d598207",
      "1bc2c69f2e13417f8b8d28cfc518b4ff",
      "9fe14a4123894218a31ee4df81ece066",
      "ea0b8a8aa9a1459f93bd362c173775ae",
      "db85e609df9241078683bc938725225c",
      "af98f7d71d8345bf93ad2623705dc97e",
      "653877b0826740fdb38f364f85c1ddf0",
      "13c949b613564aaeb32cec9d02d39b08",
      "7ebfdd27f7614ae4b00c72b395669d96"
     ]
    },
    "id": "jF9rZAbxNXqM",
    "outputId": "df6fc1f7-280e-4c5c-fc2f-063b1635215f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fe6b6435a1434e8933f91418459a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#INITIATE MODEL\n",
    "from transformers import AutoModelForSpeechSeq2Seq\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id,\n",
    "                                                           num_labels=2,\n",
    "                                                           ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ftfsE2Aq4gsi"
   },
   "outputs": [],
   "source": [
    "#SETIING UP TRAINING ARGUMENTS\n",
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "                output_dir=\"./SentimentAnalysis\",\n",
    "                save_strategy=\"epoch\",\n",
    "                eval_strategy=\"epoch\",\n",
    "                learning_rate=2e-5,\n",
    "                per_device_train_batch_size=16,\n",
    "                per_device_eval_batch_size=16,\n",
    "                num_train_epochs=2,\n",
    "                weight_decay=.01,\n",
    "                load_best_model_at_end=True,\n",
    "                logging_dir=\"./Logs\",\n",
    "                logging_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHJg8mjTF1mw",
    "outputId": "cdf6184d-ac14-4fbc-a66c-073755eda732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.34.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.5\n"
     ]
    }
   ],
   "source": [
    "#SETTING UP METRIC FUNCTION\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "0o8PJkfXL8uW"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "  '''\n",
    "  compute accuracy\n",
    "  '''\n",
    "  logits, label = eval_preds\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  return accuracy.compute(predictions=predictions, references=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "rOBnAuhyNUq9",
    "outputId": "2f5786e2-0ca7-4ff2-a3d5-5f45f0aa1d52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moluwayomidaniel139\u001b[0m (\u001b[33moluwayomidaniel139-self\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250821_201030-0ao62jfg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oluwayomidaniel139-self/huggingface/runs/0ao62jfg' target=\"_blank\">fresh-violet-1</a></strong> to <a href='https://wandb.ai/oluwayomidaniel139-self/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oluwayomidaniel139-self/huggingface' target=\"_blank\">https://wandb.ai/oluwayomidaniel139-self/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oluwayomidaniel139-self/huggingface/runs/0ao62jfg' target=\"_blank\">https://wandb.ai/oluwayomidaniel139-self/huggingface/runs/0ao62jfg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='276' max='276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [276/276 05:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.281207</td>\n",
       "      <td>0.876667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.386670</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=276, training_loss=0.27608868695687555, metrics={'train_runtime': 584.8269, 'train_samples_per_second': 7.524, 'train_steps_per_second': 0.472, 'total_flos': 578844321792000.0, 'train_loss': 0.27608868695687555, 'epoch': 2.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INITIALIZE TRAINER\n",
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "            args=training_args,\n",
    "            model=model,\n",
    "            train_dataset=small_train_dataset,\n",
    "            eval_dataset=small_test_dataset,\n",
    "            compute_metrics=compute_metrics )\n",
    "\n",
    "#Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "XSXtNfl0MI0X",
    "outputId": "15a12835-fbc8-4b61-f515-1289fdd0ff16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2812069356441498,\n",
       " 'eval_accuracy': 0.8766666666666667,\n",
       " 'eval_runtime': 17.5777,\n",
       " 'eval_samples_per_second': 68.268,\n",
       " 'eval_steps_per_second': 4.267,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = trainer.evaluate(small_test_dataset)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vw-0_w6hWSUQ"
   },
   "source": [
    "<h2>SETTING UP PREDICTION FUNCTION</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "jKG27yl8U23G"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# map labels to text\n",
    "label_map = {0: \"Negative 😡\", 1: \"Positive 😀\"}\n",
    "\n",
    "# set device and move model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # tokenize input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  # move inputs to device\n",
    "\n",
    "    # run through model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # pick label\n",
    "    predicted_class = torch.argmax(probs).item()\n",
    "    confidence = probs[0][predicted_class].item()\n",
    "\n",
    "    return f\"{label_map[predicted_class]} (confidence: {confidence:.2f})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "p9mtcIXTWeoc",
    "outputId": "991eb00e-d3d7-4bf5-9289-80d8562d276b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Positive 😀 (confidence: 0.96)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"This product absolutely redefines expectations. I’ve never seen something commit so fully to its own interpretation of functionality. The design choices are bold—some might say avant-garde—and the user experience is unforgettable, in the sense that it leaves a lasting impression, much like stepping on a LEGO. Every feature works in a way that challenges conventional logic, encouraging users to think differently, or sometimes not at all. It’s refreshingly unpredictable, and the way it handles tasks is truly one-of-a-kind. I wouldn’t hesitate to recommend it to anyone who enjoys surprises, especially the kind that make you question your life choices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0-y7Ugtbjqr"
   },
   "source": [
    "<h2>Saving and Loading the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14X6-iKwabSr",
    "outputId": "391b8aa6-4cd5-46ee-8ece-6c5c2c86b48a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment_analysis_model/tokenizer_config.json',\n",
       " './sentiment_analysis_model/special_tokens_map.json',\n",
       " './sentiment_analysis_model/vocab.txt',\n",
       " './sentiment_analysis_model/added_tokens.json',\n",
       " './sentiment_analysis_model/tokenizer.json')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SAVING THE MODEL\n",
    "model.save_pretrained(\"./sentiment_analysis_model\")\n",
    "tokenizer.save_pretrained(\"./sentiment_analysis_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "5ZD8MYRfb4G3"
   },
   "outputs": [],
   "source": [
    "#LOADING THE MODEL\n",
    "my_tokenizer = AutoTokenizer.from_pretrained(\"./sentiment_analysis_model\")\n",
    "my_model = AutoModelForSequenceClassification.from_pretrained(\"./sentiment_analysis_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k1Qp_LSefFR"
   },
   "source": [
    "<h2>Pushing Model To Hugging Face Hub</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "56ecff53b3a24c95a75bced3ecc7bb38",
      "d026829986af4d99a54782dabc0efa76",
      "f9cd2ed30e784897aa8e3d6d17ba5308",
      "4d072d4e47a84ebda89ce64d9a38b570",
      "bfc5dd746f654d9a877cfe24de8956e1",
      "1be2a6373f264aa4b1932512e5f0a3a2",
      "9a9fd17af512469cb230af67c4abb817",
      "f55fe7488fce4b9ea439abfccdb23e5c",
      "85603ceecced43a1b0bf5c188a1baa5d",
      "1c1c737e30e84bef910ca34a695aba0c",
      "84e8363b5b2e4a7c9610fd68f56719a9",
      "c1cec5ed8085456d866f1c8e39c8c973",
      "0e4e384f536542059f54d35928590bf6",
      "26b32eb231284443990962febfc4b8d3",
      "65c4ce783b634c95a285c3fe3b5e2ec1",
      "47a872d1e5664cda8ae10766451f6d81",
      "1da80f4f80b54c009bfc93302c4043dd",
      "d227966c07a84a1fa1165195f7a9a7bd",
      "c5cbcc75737f43fa83f021a7af03c3fb",
      "28575f789e4c435da00fa09be7a1e5ed"
     ]
    },
    "id": "1Y9PEdrkeaO2",
    "outputId": "cba625a0-9095-45f4-8615-56e0f9ac79d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ecff53b3a24c95a75bced3ecc7bb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "d320f066db1d4f07ab25c2e3abccbc36",
      "182b42e29362458bb346ef6e7ba37696",
      "3050af3816844f0e83d9b5c4570317bf",
      "2d620f8dc2954791b48fde4494951846",
      "0f4f62435f19431eb53abbf7470945d8",
      "689b17cd57c04654b97c4b28db2fd576",
      "20f4dab72ee141e2bed6fa5ef56347e1",
      "c03fe039c11747c1bbfd3212f19ea5ec",
      "1eaaadd804ff447993a8532ebc57196a",
      "2aaa4fc37daf478080823b46e6306bef",
      "3d8daf925c734383bb21f412638a9e60",
      "69780db1e09e4d6f855ba1665396b140",
      "19a33aca54144875a0e421ba068483d6",
      "811345d39e7040ada2cf25317116d978",
      "cf3c21641f524a58876aed9384938766",
      "a63daee0fee24815b4aed7213760d6e2",
      "31f5efb82f7645288bda91afb22cbeff",
      "b3e2362ead4d496499ead02f1f5ce735",
      "e6251303cd13493ba4e411a4cbdfe8a8",
      "8fbfdb64295f4c6ebb9549e50a4bfd88",
      "44fa7c3b622642e4bee268db21d2ec54",
      "f3587706342b4c49a5d789c9cd791f00",
      "4b5f5f49aca34437b2204b4b52d51c65",
      "b5190050f02e4e289a70a3ff1b35a6b3",
      "ce2ed09d18f6435abf97f93bd00b3b10",
      "455317335e934959b6ca891303ac47fd",
      "92175fec99db4143a10479df08a69770",
      "d69b720d4da34a069f8c28f53d94f133",
      "5ed0036d868b47f2bc9fc9a92b1aee48",
      "517e4abbc1254ee498202d85e3621db3",
      "2a763d8846c046ec81a5754a5efc834b",
      "69daf9a862944a72908dcb11fe03d556",
      "6d2f8d164a094492b80cf36a7a4479b0",
      "8e113cb925144b53993d5c0cbcdc9368",
      "7b3caa022b6a472cb32a7aa32730e640",
      "6065c397e0e94cb79174f5f908971145",
      "d235009577c44d9b91d952392cca8199",
      "d8d153fcb2ec4b6fbc26adfd31a6fc1e",
      "837201d87e424c5e877d9a8ea92124dd",
      "36ee41a156124468a2c7f946a12592fb",
      "a28b4fbf38564d8390eed559da6c5fb1",
      "4762711b65704ff294af04c03dff80e0",
      "33ded69a69724999a141d16a8503a439",
      "95d0c8c76f97438399a420787f640b31"
     ]
    },
    "id": "u6YOyN0-eyEF",
    "outputId": "0c88aac8-fb62-4469-f1d7-ac9dce3158b0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d320f066db1d4f07ab25c2e3abccbc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69780db1e09e4d6f855ba1665396b140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5f5f49aca34437b2204b4b52d51c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  /tmp/tmp2sa6vvvu/model.safetensors    :   0%|          | 14.2kB /  669MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e113cb925144b53993d5c0cbcdc9368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Yomex139/imdb-sentiment-model/commit/9948520185e2f4e91ea6d3fb15f44583eec62f4a', commit_message='Upload tokenizer', commit_description='', oid='9948520185e2f4e91ea6d3fb15f44583eec62f4a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Yomex139/imdb-sentiment-model', endpoint='https://huggingface.co', repo_type='model', repo_id='Yomex139/imdb-sentiment-model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_id = \"Yomex139/imdb-sentiment-model\"\n",
    "# my_model.push_to_hub(model_id)\n",
    "# my_tokenizer.push_to_hub(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "MdJFpoDKg4MU"
   },
   "outputs": [],
   "source": [
    "app_code = \"\"\"\n",
    "# app.py\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import gradio as gr\n",
    "\n",
    "# Set your model repo on the Hub\n",
    "MODEL_ID = \"Yomex139/imdb-sentiment-model\"\n",
    "\n",
    "# make CPU inference a bit more stable on Spaces\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "# Load once at startup (cached by HF Spaces)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID)\n",
    "model.eval()\n",
    "\n",
    "LABELS = {0: \"Negative 😡\", 1: \"Positive 😀\"}\n",
    "\n",
    "def predict(text):\n",
    "    if not text or not text.strip():\n",
    "        return {\"label\": \"—\", \"confidence\": 0.0}\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = torch.softmax(logits, dim=-1)[0]\n",
    "        pred_id = int(torch.argmax(probs))\n",
    "        conf = float(probs[pred_id])\n",
    "    return {\"label\": LABELS[pred_id], \"confidence\": round(conf, 4)}\n",
    "\n",
    "def ui_predict(text):\n",
    "    out = predict(text)\n",
    "    return f\"{out['label']}  (confidence: {out['confidence']:.2f})\"\n",
    "\n",
    "examples = [\n",
    "    \"This movie was absolutely wonderful, I loved every second of it!\",\n",
    "    \"The film was terrible, boring and a complete waste of time.\",\n",
    "    \"Not the best, not the worst. Just okay.\",\n",
    "]\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=ui_predict,\n",
    "    inputs=gr.Textbox(lines=4, label=\"Enter a movie review\"),\n",
    "    outputs=gr.Textbox(label=\"Prediction\"),\n",
    "    title=\"IMDB Sentiment Classifier\",\n",
    "    description=\"DistilBERT fine-tuned on IMDB. Type a review and get Positive/Negative with confidence.\",\n",
    "    examples=[[e] for e in examples],\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n",
    "\"\"\"\n",
    "with open(\"app.py\", \"w\") as f:\n",
    "  f.write(app_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "1924c4cc434a402ca682669a8eaad45f",
      "78724400ae7347f88440e4b706fbcf2e",
      "b7566dcbdff340f9b320f4078ce4dc2d",
      "4d52fd0288ff414aa3778edc56dcce84",
      "013ea3069b7241a2b3fad56add30e704",
      "88b7d8cef16e447b82238387365d744a",
      "1dfe5dd752b44f72b5a707f657854a0b",
      "5c989a236bfb40cd9beef98b6b7621c2",
      "5c48a7beb138450199e096f906dbe59c",
      "04dc37688d7040b59fcca2b5edeb4a53",
      "01a06346cbea4fe3ae6787f34f2f12ef",
      "2fc0ac248bbe45ab895378d2eb9df43a",
      "74fd13bcdbaf40708b6e99c0b3bf87f0",
      "06139c39b5484999b7c92b98ac3daf8c",
      "106842f2fd5b4058a57ac0e533032779",
      "658ebff4ed544d25b6eed76a0814b44b",
      "a71cbe4470cf4ca99cd96268e14aba5d",
      "d55ddf53254544079c679065240a5311",
      "3d918ab834e34327b5b2da657924b105",
      "69f425a15de24d1a946e1e8d4978b144"
     ]
    },
    "id": "75S6FTYxkjnw",
    "outputId": "5c191c92-c5b8-4e8a-a80f-5c9a74ce5bd6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1924c4cc434a402ca682669a8eaad45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162,
     "referenced_widgets": [
      "c0cdc4b99eee4b9ea046c83068995f2e",
      "4792bc2c7e2e411bbb7b7054d418f3dc",
      "9b51b028bdfc451ca0f1af1038c591c9",
      "6d4d085cfe3d438b8cebd5e9064d82f4",
      "bcd684061b2447ec81381330259de01c",
      "da61bb355c4c4c8abc02623ab6220dd1",
      "06d88a61876e4e9e9bcf4adee21449b1",
      "f0c02893a84c438ba1a842827ea5f592",
      "8403d510d18748209b1356969023dd81",
      "5cbd6a8665e74d6fbf1ac8cadb38fd76",
      "c26cfdd7361042c3abda9f700c410ac1",
      "e1a34f6e5e1a4b9899e0f0fa774f90e7",
      "a9741671ed0d4116a79e0a0304b5d62c",
      "29caeb4d8f8941b3bce78576f9ec35a8",
      "badd328a1a0a4a949dd2fb9cbcdee08d",
      "fc638dd6959048f889b42874bfa7cdcf",
      "eef27f6020cf4c0e9b8140786bd46941",
      "c7aa8a73a0d84df7b0f28015466d40b1",
      "9b2ffd0d40d641df9c86d37758299b03",
      "9d3b3831153644918e285f0d87d26040",
      "7778da91b61544639ab253f9c22d3948",
      "146da8e8cc6643e1ac88e270b6b53764",
      "b351722f0d21410590941289909245b9",
      "06c0079e5a694197bb74813164a27bda",
      "ceba93597a6f4adc97c7c7daca50dc09",
      "a1a0c99acde343f1b4b7a86bb728af1d",
      "4e99010e0bfd44899086373db49bbe48",
      "1fa7225fdb384dea8b2cb040a96fb6c5",
      "8e4d4c6746794ab9a2d1a37c9091b937",
      "7db8956681674cf680a1186492631e02",
      "13a5a391df5641328b4be01d375a0a2f",
      "72d8da25f24148c29ef5318759083eb3",
      "c64268f9e6924c1f8310d21821ba8044",
      "4bc43bf84f744f6bae35097cfec0987d",
      "7becf62e57ca480885bfac973e9dfc2e",
      "40252274b8ae42a3bb5dab967fe391e2",
      "6017917b6fc74cd883eb8ebebf9eaf81",
      "1e46271784d8473d9a30f6f6a5c6bc1c",
      "17f4da1926ef4286993efcf5ee16b9b3",
      "2e8d7f948f6e46ada69649dbce489ac2",
      "8b95569bec1f4132acdede650ae06f1f",
      "df81afbb5b214401a369dece406eec40",
      "da6cbfe679e1453f98c5b34e0dae0af0",
      "7e3319a5c02047bfb1860f9efc3951d7"
     ]
    },
    "id": "_eAKZN6flGYj",
    "outputId": "3a5b49d8-199e-4157-b73d-0c6e9244b121"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cdc4b99eee4b9ea046c83068995f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a34f6e5e1a4b9899e0f0fa774f90e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b351722f0d21410590941289909245b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...t/sample_data/mnist_train_small.csv:  23%|##2       | 8.34MB / 36.5MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc43bf84f744f6bae35097cfec0987d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  /content/sample_data/mnist_test.csv   : 100%|##########| 18.3MB / 18.3MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space pushed! Visit on Hugging Face to see the build logs.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, create_repo, upload_folder\n",
    "from pathlib import Path\n",
    "\n",
    "api = HfApi()\n",
    "space_id = \"Yomex139/imdb-sentiment-app\"\n",
    "\n",
    "# 1) Create a Space (type='space') with Gradio\n",
    "create_repo(\n",
    "    repo_id=space_id,\n",
    "    repo_type=\"space\",\n",
    "    space_sdk=\"gradio\",\n",
    "    private=False,  # set True if you want it private\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "# 2) Write files locally\n",
    "Path(\"app.py\").write_text(open(\"/content/app.py\").read() if Path(\"/content/app.py\").exists() else \"\"\"# app.py\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import gradio as gr\n",
    "\n",
    "# Set your model repo on the Hub\n",
    "MODEL_ID = \"Yomex139/imdb-sentiment-model\"\n",
    "\n",
    "# make CPU inference a bit more stable on Spaces\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "# Load once at startup (cached by HF Spaces)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID)\n",
    "model.eval()\n",
    "\n",
    "LABELS = {0: \"Negative 😡\", 1: \"Positive 😀\"}\n",
    "\n",
    "def predict(text):\n",
    "    if not text or not text.strip():\n",
    "        return {\"label\": \"—\", \"confidence\": 0.0}\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = torch.softmax(logits, dim=-1)[0]\n",
    "        pred_id = int(torch.argmax(probs))\n",
    "        conf = float(probs[pred_id])\n",
    "    return {\"label\": LABELS[pred_id], \"confidence\": round(conf, 4)}\n",
    "\n",
    "def ui_predict(text):\n",
    "    out = predict(text)\n",
    "    return f\"{out['label']}  (confidence: {out['confidence']:.2f})\"\n",
    "\n",
    "examples = [\n",
    "    \"This movie was absolutely wonderful, I loved every second of it!\",\n",
    "    \"The film was terrible, boring and a complete waste of time.\",\n",
    "    \"Not the best, not the worst. Just okay.\",\n",
    "]\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=ui_predict,\n",
    "    inputs=gr.Textbox(lines=4, label=\"Enter a movie review\"),\n",
    "    outputs=gr.Textbox(label=\"Prediction\"),\n",
    "    title=\"IMDB Sentiment Classifier\",\n",
    "    description=\"DistilBERT fine-tuned on IMDB. Type a review and get Positive/Negative with confidence.\",\n",
    "    examples=[[e] for e in examples],\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\"\"\")\n",
    "Path(\"requirements.txt\").write_text(\"\"\"transformers>=4.41.0\n",
    "torch\n",
    "gradio>=4.24.0\n",
    "\"\"\")\n",
    "Path(\"README.md\").write_text(\"\"\"---\n",
    "title: IMDB Sentiment Classifier\n",
    "emoji: 💬\n",
    "colorFrom: indigo\n",
    "colorTo: green\n",
    "sdk: gradio\n",
    "sdk_version: 4.24.0\n",
    "python_version: 3.10\n",
    "app_file: app.py\n",
    "pinned: false\n",
    "license: apache-2.0\n",
    "---\n",
    "\n",
    "A simple Gradio app using a DistilBERT model fine-tuned on the IMDB dataset to classify movie reviews as Positive or Negative.\n",
    "\"\"\")\n",
    "\n",
    "# 3) Upload folder contents to the Space\n",
    "upload_folder(\n",
    "    repo_id=space_id,\n",
    "    folder_path=\".\",           # current folder with app.py/requirements/README\n",
    "    repo_type=\"space\",\n",
    "    ignore_patterns=[\"**/.ipynb_checkpoints/**\", \"**/__pycache__/**\", \".git/**\"]\n",
    ")\n",
    "\n",
    "print(\"Space pushed! Visit on Hugging Face to see the build logs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9majneg4wlrN",
    "outputId": "27f4f2a7-e3c9-426f-bbdd-86a6c64beae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ],
   "source": [
    "!git config --global user.email \"youremail@example.com\"\n",
    "!git config --global user.name \"yourusername\"\n",
    "\n",
    "!git add runtime.txt\n",
    "!git commit -m \"Add runtime.txt for Python 3.9\"\n",
    "!git push\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rc7r6yxwwnrR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
